{
  "cells": [
    {
      "metadata": {
        "_uuid": "2bba6a15c8e257d2ac514ab85cd2cc92ed213ba2"
      },
      "cell_type": "markdown",
      "source": "## Medium post: https://medium.com/@gabogarza/exoplanet-hunting-with-machine-learning-and-kepler-data-recall-100-155e1ddeaa95\n\n## Github repo: https://github.com/gabrielgarza/exoplanet-deep-learning"
    },
    {
      "metadata": {
        "_uuid": "b6b2254965f03e535cb73f1abf3bba4ec5c3cfe4"
      },
      "cell_type": "markdown",
      "source": "### Import libraries"
    },
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\nimport time\nfrom pathlib import Path\nfrom sklearn import cross_validation\nfrom sklearn.metrics import classification_report\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.svm import LinearSVC\nfrom scipy import ndimage, fft\nfrom sklearn.preprocessing import normalize\nimport os\nprint(os.listdir(\"../input\"))",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['exoTest.csv', 'exoTrain.csv']\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "d28cb86655c3af600b8377e7de783c488c2e3676"
      },
      "cell_type": "markdown",
      "source": "## Data Preprocessor"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "87e08df975d26a6d05feb1005931fa20ad450fde"
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom scipy import ndimage, fft\nfrom sklearn.preprocessing import normalize, StandardScaler, MinMaxScaler\n\nclass LightFluxProcessor:\n\n    def __init__(self, fourier=True, normalize=True, gaussian=True, standardize=True):\n        self.fourier = fourier\n        self.normalize = normalize\n        self.gaussian = gaussian\n        self.standardize = standardize\n\n    def fourier_transform(self, X):\n        return np.abs(fft(X, n=X.size))\n\n    def process(self, df_train_x, df_dev_x):\n        # Apply fourier transform\n        if self.fourier:\n            print(\"Applying Fourier...\")\n            df_train_x = df_train_x.apply(self.fourier_transform,axis=1)\n            df_dev_x = df_dev_x.apply(self.fourier_transform,axis=1)\n\n            # Keep first half of data as it is symmetrical after previous steps\n            df_train_x = df_train_x.iloc[:,:(df_train_x.shape[1]//2)].values\n            df_dev_x = df_dev_x.iloc[:,:(df_dev_x.shape[1]//2)].values\n\n        # Normalize\n        if self.normalize:\n            print(\"Normalizing...\")\n            df_train_x = pd.DataFrame(normalize(df_train_x))\n            df_dev_x = pd.DataFrame(normalize(df_dev_x))\n\n        # Gaussian filter to smooth out data\n        if self.gaussian:\n            print(\"Applying Gaussian Filter...\")\n            df_train_x = ndimage.filters.gaussian_filter(df_train_x, sigma=10)\n            df_dev_x = ndimage.filters.gaussian_filter(df_dev_x, sigma=10)\n\n        if self.standardize:\n            # Standardize X data\n            print(\"Standardizing...\")\n            std_scaler = StandardScaler()\n            df_train_x = std_scaler.fit_transform(df_train_x)\n            df_dev_x = std_scaler.transform(df_dev_x)\n\n        print(\"Finished Processing!\")\n        return df_train_x, df_dev_x\n",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c17634d1b3ecb3fd7b361d19c8774df26dac4ea2"
      },
      "cell_type": "markdown",
      "source": "### Load datasets"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8aef4d6898bf06a2414a3a675a1fa9400f97cbd6"
      },
      "cell_type": "code",
      "source": "train_dataset_path = \"../input/exoTrain.csv\"\ndev_dataset_path = \"../input/exoTest.csv\"\n\nprint(\"Loading datasets...\")\ndf_train = pd.read_csv(train_dataset_path, encoding = \"ISO-8859-1\")\ndf_dev = pd.read_csv(dev_dataset_path, encoding = \"ISO-8859-1\")\nprint(\"Loaded datasets!\")\n\n# Generate X and Y dataframe sets\ndf_train_x = df_train.drop('LABEL', axis=1)\ndf_dev_x = df_dev.drop('LABEL', axis=1)\ndf_train_y = df_train.LABEL\ndf_dev_y = df_dev.LABEL",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Loading datasets...\nLoaded datasets!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "3e03e00f593729a6fb36841cde640a0cb366bf4f"
      },
      "cell_type": "markdown",
      "source": "### Process data and create numpy matrices"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "504e0ecddfafc27cdf49022f2950566373c0d6fe"
      },
      "cell_type": "code",
      "source": "def np_X_Y_from_df(df):\n    df = shuffle(df)\n    df_X = df.drop(['LABEL'], axis=1)\n    X = np.array(df_X)\n    Y_raw = np.array(df['LABEL']).reshape((len(df['LABEL']),1))\n    Y = Y_raw == 2\n    return X, Y",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "90a0ea43b0ef441d5ff094adec4d6a1e2030ab58"
      },
      "cell_type": "code",
      "source": "# Process dataset\nLFP = LightFluxProcessor(\n    fourier=True,\n    normalize=True,\n    gaussian=True,\n    standardize=True)\ndf_train_x, df_dev_x = LFP.process(df_train_x, df_dev_x)\n\n# Rejoin X and Y\ndf_train_processed = pd.DataFrame(df_train_x).join(pd.DataFrame(df_train_y))\ndf_dev_processed = pd.DataFrame(df_dev_x).join(pd.DataFrame(df_dev_y))\n\n# Load X and Y numpy arrays\nX_train, Y_train = np_X_Y_from_df(df_train_processed)\nX_dev, Y_dev = np_X_Y_from_df(df_dev_processed)",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Applying Fourier...\nNormalizing...\nApplying Gaussian Filter...\nStandardizing data...\nFinished Processing!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "0eb999422374f71b0f44292382dee19239332f37"
      },
      "cell_type": "markdown",
      "source": "### Describe datasets"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "744f7863433eb3b36ca7e93abd2311dd658c790b"
      },
      "cell_type": "code",
      "source": "(num_examples, n_x) = X_train.shape # (n_x: input size, m : number of examples in the train set)\nn_y = Y_train.shape[1] # n_y : output size\nprint(\"X_train.shape: \", X_train.shape)\nprint(\"Y_train.shape: \", Y_train.shape)\nprint(\"X_dev.shape: \", X_dev.shape)\nprint(\"Y_dev.shape: \", Y_dev.shape)\nprint(\"n_x: \", n_x)\nprint(\"num_examples: \", num_examples)\nprint(\"n_y: \", n_y)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "X_train.shape:  (5087, 1598)\nY_train.shape:  (5087, 1)\nX_dev.shape:  (570, 1598)\nY_dev.shape:  (570, 1)\nn_x:  1598\nnum_examples:  5087\nn_y:  1\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "b4783cdb1902414c346e39c709b5619788e4b748"
      },
      "cell_type": "markdown",
      "source": "## Build Model, Train, and Predict"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cea07ef250b87a2d326410dd5985e9cec1517c46"
      },
      "cell_type": "code",
      "source": "model = LinearSVC()\n\n# sm = SMOTE(ratio = 1.0)\n# X_train_sm, Y_train_sm = sm.fit_sample(X_train, Y_train)\nX_train_sm, Y_train_sm = X_train, Y_train\n\n# Train\nprint(\"Training...\")\nmodel.fit(X_train_sm, Y_train_sm)\n\ntrain_outputs = model.predict(X_train_sm)\ndev_outputs = model.predict(X_dev)\nprint(\"Finished Training!\")",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Training...\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "1d89125e42171a7bfda48da4313b92ca0b04d866"
      },
      "cell_type": "markdown",
      "source": "## Calculate and Display Metrics"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9e3b8584de8273df5d255d6cd0eebbb0590c458c"
      },
      "cell_type": "code",
      "source": "# Metrics\ntrain_outputs = model.predict(X_train_sm)\ndev_outputs = model.predict(X_dev)\ntrain_outputs = np.rint(train_outputs)\ndev_outputs = np.rint(dev_outputs)\naccuracy_train = accuracy_score(Y_train_sm, train_outputs)\naccuracy_dev = accuracy_score(Y_dev, dev_outputs)\nprecision_train = precision_score(Y_train_sm, train_outputs)\nprecision_dev = precision_score(Y_dev, dev_outputs)\nrecall_train = recall_score(Y_train_sm, train_outputs)\nrecall_dev = recall_score(Y_dev, dev_outputs)\nconfusion_matrix_train = confusion_matrix(Y_train_sm, train_outputs)\nconfusion_matrix_dev = confusion_matrix(Y_dev, dev_outputs)\nclassification_report_train = classification_report(Y_train_sm, train_outputs)\nclassification_report_dev = classification_report(Y_dev, dev_outputs)\n\nprint(\" \")\nprint(\" \")\nprint(\"Train Set Error\", 1.0 - accuracy_train)\nprint(\"Dev Set Error\", 1.0 - accuracy_dev)\nprint(\"------------\")\nprint(\"Precision - Train Set\", precision_train)\nprint(\"Precision - Dev Set\", precision_dev)\nprint(\"------------\")\nprint(\"Recall - Train Set\", recall_train)\nprint(\"Recall - Dev Set\", recall_dev)\nprint(\"------------\")\nprint(\"Confusion Matrix - Train Set\")\nprint(confusion_matrix_train)\nprint(\"Confusion Matrix - Dev Set\")\nprint(confusion_matrix_dev)\nprint(\"------------\")\nprint(\" \")\nprint(\" \")\nprint(\"------------\")\nprint(\"classification_report_train\")\nprint(classification_report_train)\nprint(\"classification_report_dev\")\nprint(classification_report_dev)",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": " \n \nTrain Set Error 0.0\nDev Set Error 0.007017543859649145\n------------\nPrecision - Train Set 1.0\nPrecision - Dev Set 0.5555555555555556\n------------\nRecall - Train Set 1.0\nRecall - Dev Set 1.0\n------------\nConfusion Matrix - Train Set\n[[5050    0]\n [   0   37]]\nConfusion Matrix - Dev Set\n[[561   4]\n [  0   5]]\n------------\n \n \n------------\nclassification_report_train\n             precision    recall  f1-score   support\n\n      False       1.00      1.00      1.00      5050\n       True       1.00      1.00      1.00        37\n\navg / total       1.00      1.00      1.00      5087\n\nclassification_report_dev\n             precision    recall  f1-score   support\n\n      False       1.00      0.99      1.00       565\n       True       0.56      1.00      0.71         5\n\navg / total       1.00      0.99      0.99       570\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "1b8f75a0a1976000bc34e71a65c512d124825097"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}